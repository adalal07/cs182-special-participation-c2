{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfIADVN5GxoM"
      },
      "source": [
        "# Implement Transformer from Scratch\n",
        "\n",
        "In this coding homework, you will:\n",
        "\n",
        "- Implement a simple transformer model from scratch to enhance your understanding of how it works.\n",
        "- Create a hand-designed transformer model capable of solving a basic problem. This will help you comprehend the various operations that transformers can perform.\n",
        "- Analyze the attention patterns of a trained network to gain insights into how learned models often utilize features that differ greatly from those employed by humans.\n",
        "\n",
        "Please note that a GPU is not necessary for this task. If you're using Colab, you can select the \"Runtime\" -> \"Change runtime type\" menu and choose \"None\" as the hardware accelerator.\n",
        "\n",
        "**Note:** The same variables will be defined in different ways in various subparts of the homework. If you encounter errors stating that a variable has the wrong shape or a function is missing an argument, ensure that you have re-run the cells in that particular problem subpart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOxMLCmxGxoN"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Setup, Configuration, and Helper Functions\n",
        "===========================================\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import time\n",
        "import json\n",
        "import inspect\n",
        "import random\n",
        "import math\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Callable, Optional, Tuple, List, Any\n",
        "\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.axes import Axes\n",
        "from matplotlib.figure import Figure\n",
        "\n",
        "# =============================================================================\n",
        "# Type Aliases\n",
        "# =============================================================================\n",
        "NDArrayFloat = npt.NDArray[np.floating[Any]]\n",
        "TensorFloat = torch.Tensor\n",
        "\n",
        "# =============================================================================\n",
        "# Configuration Classes\n",
        "# =============================================================================\n",
        "@dataclass\n",
        "class PlotConfig:\n",
        "    \"\"\"Configuration for matplotlib plots.\"\"\"\n",
        "    # Figure settings\n",
        "    figure_width: float = 20.0\n",
        "    figure_height: float = 5.0\n",
        "    dpi: int = 100\n",
        "    \n",
        "    # Colormap settings\n",
        "    colormap: str = \"Reds\"\n",
        "    vmin: Optional[float] = None\n",
        "    vmax: Optional[float] = None\n",
        "    \n",
        "    # Text settings\n",
        "    title_fontsize: int = 12\n",
        "    label_fontsize: int = 10\n",
        "    \n",
        "    # Axis settings\n",
        "    show_xticks: bool = False\n",
        "    show_yticks: bool = False\n",
        "    tight_layout: bool = True\n",
        "    \n",
        "    # Grid settings\n",
        "    nrows: int = 1\n",
        "    ncols: int = 8\n",
        "    \n",
        "    # Save settings\n",
        "    save_dir: str = \"plots\"\n",
        "    save_format: str = \"png\"  # \"png\", \"pdf\", \"svg\"\n",
        "    save_dpi: int = 150\n",
        "    auto_save: bool = False  # If True, automatically save all plots\n",
        "    add_timestamp: bool = True  # Add timestamp to filenames\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    \"\"\"Configuration for training loop.\"\"\"\n",
        "    num_epochs: int = 10_001\n",
        "    learning_rate: float = 3e-2\n",
        "    log_interval: int = 1000\n",
        "    optimizer: str = \"sgd\"  # \"sgd\" or \"adam\"\n",
        "    momentum: float = 0.0\n",
        "    weight_decay: float = 0.0\n",
        "    loss_fn: str = \"mse\"  # \"mse\" or \"cross_entropy\"\n",
        "\n",
        "\n",
        "# Default configurations\n",
        "PLOT_CONFIG = PlotConfig()\n",
        "TRAIN_CONFIG = TrainingConfig()\n",
        "plt.rcParams['figure.figsize'] = [PLOT_CONFIG.figure_width, PLOT_CONFIG.figure_height]\n",
        "plt.rcParams['figure.dpi'] = PLOT_CONFIG.dpi\n",
        "\n",
        "# Constants\n",
        "RELATIVE_TOLERANCE = 1e-3\n",
        "TEST_ITERATIONS = 10\n",
        "TEST_MIN_SEQ_LEN = 1\n",
        "TEST_MAX_SEQ_LEN = 4\n",
        "TEST_INPUT_DIM = 5\n",
        "\n",
        "# =============================================================================\n",
        "# Utility Functions\n",
        "# =============================================================================\n",
        "def set_random_seed(seed: int = 42) -> None:\n",
        "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "_set_seed = set_random_seed  # Backward compatibility\n",
        "\n",
        "# =============================================================================\n",
        "# Visualization Functions\n",
        "# =============================================================================\n",
        "def rescale_and_plot(\n",
        "    arr: NDArrayFloat,\n",
        "    title: str = '',\n",
        "    ax: Optional[Axes] = None,\n",
        "    x_lab: Optional[str] = None,\n",
        "    y_lab: Optional[str] = None,\n",
        "    colormap: str = PLOT_CONFIG.colormap,\n",
        "    vmin: Optional[float] = PLOT_CONFIG.vmin,\n",
        "    vmax: Optional[float] = PLOT_CONFIG.vmax,\n",
        "    title_fontsize: int = PLOT_CONFIG.title_fontsize,\n",
        "    label_fontsize: int = PLOT_CONFIG.label_fontsize,\n",
        "    show_xticks: bool = PLOT_CONFIG.show_xticks,\n",
        "    show_yticks: bool = PLOT_CONFIG.show_yticks,\n",
        ") -> None:\n",
        "    \"\"\"Plot a matrix as a heatmap with automatic [0, 1] rescaling.\"\"\"\n",
        "    assert arr.ndim == 2, f\"arr must be 2D, got shape {arr.shape}\"\n",
        "    \n",
        "    # Rescale to [0, 1]\n",
        "    arr = arr - arr.min()\n",
        "    if arr.max() > 0:\n",
        "        arr = arr / arr.max()\n",
        "    \n",
        "    ax.imshow(arr, cmap=colormap, vmin=vmin, vmax=vmax)\n",
        "    ax.set_title(title, fontsize=title_fontsize)\n",
        "    \n",
        "    if not show_xticks:\n",
        "        ax.set_xticks([])\n",
        "    if not show_yticks:\n",
        "        ax.set_yticks([])\n",
        "    if x_lab is not None:\n",
        "        ax.set_xlabel(x_lab, fontsize=label_fontsize)\n",
        "    if y_lab is not None:\n",
        "        ax.set_ylabel(y_lab, fontsize=label_fontsize)\n",
        "\n",
        "\n",
        "def save_figure(\n",
        "    fig: Figure,\n",
        "    name: str,\n",
        "    save_dir: str = PLOT_CONFIG.save_dir,\n",
        "    save_format: str = PLOT_CONFIG.save_format,\n",
        "    save_dpi: int = PLOT_CONFIG.save_dpi,\n",
        "    add_timestamp: bool = PLOT_CONFIG.add_timestamp,\n",
        "    run_name: Optional[str] = None,\n",
        ") -> Path:\n",
        "    \"\"\"Save a matplotlib figure to the plots directory.\n",
        "    \n",
        "    Args:\n",
        "        fig: Matplotlib figure to save.\n",
        "        name: Base name for the file (without extension).\n",
        "        save_dir: Directory to save plots (created if doesn't exist).\n",
        "        save_format: File format (\"png\", \"pdf\", \"svg\").\n",
        "        save_dpi: Resolution for rasterized formats.\n",
        "        add_timestamp: If True, append timestamp to filename.\n",
        "        run_name: Optional run identifier to organize plots by experiment.\n",
        "    \n",
        "    Returns:\n",
        "        Path to the saved figure.\n",
        "    \"\"\"\n",
        "    # Create directory structure\n",
        "    save_path = Path(save_dir)\n",
        "    if run_name:\n",
        "        save_path = save_path / run_name\n",
        "    save_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Build filename\n",
        "    if add_timestamp:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"{name}_{timestamp}.{save_format}\"\n",
        "    else:\n",
        "        filename = f\"{name}.{save_format}\"\n",
        "    \n",
        "    filepath = save_path / filename\n",
        "    fig.savefig(filepath, dpi=save_dpi, bbox_inches='tight', format=save_format)\n",
        "    print(f\"✓ Figure saved: {filepath}\")\n",
        "    return filepath\n",
        "\n",
        "\n",
        "def get_current_figure() -> Figure:\n",
        "    \"\"\"Get the current matplotlib figure.\"\"\"\n",
        "    return plt.gcf()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Training Functions\n",
        "# =============================================================================\n",
        "def train_loop(\n",
        "    make_batch: Callable[[], Tuple[TensorFloat, TensorFloat]],\n",
        "    input_dim: int,\n",
        "    qk_dim: int,\n",
        "    v_dim: int,\n",
        "    pos_dim: Optional[int] = None,\n",
        "    max_seq_len: Optional[int] = None,\n",
        "    remove_cls: bool = False,\n",
        "    num_epochs: int = TRAIN_CONFIG.num_epochs,\n",
        "    lr: float = TRAIN_CONFIG.learning_rate,\n",
        "    log_interval: int = TRAIN_CONFIG.log_interval,\n",
        "    seed: Optional[int] = None,\n",
        ") -> Tuple['PytorchTransformer', float]:\n",
        "    \"\"\"Train a PytorchTransformer on a given task.\"\"\"\n",
        "    if seed is not None:\n",
        "        set_random_seed(seed)\n",
        "    \n",
        "    # Dimension validation\n",
        "    assert input_dim > 0, f\"input_dim must be positive, got {input_dim}\"\n",
        "    assert qk_dim > 0, f\"qk_dim must be positive, got {qk_dim}\"\n",
        "    assert v_dim > 0, f\"v_dim must be positive, got {v_dim}\"\n",
        "    \n",
        "    transformer = PytorchTransformer(input_dim, qk_dim, v_dim, pos_dim, max_seq_len)\n",
        "    optimizer = torch.optim.SGD(transformer.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    \n",
        "    final_loss = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        seq, target = make_batch()\n",
        "        \n",
        "        assert seq.dim() == 2, f\"Input must be 2D (seq_len, input_dim), got {seq.shape}\"\n",
        "        assert seq.shape[1] == input_dim, f\"Input dim mismatch: expected {input_dim}, got {seq.shape[1]}\"\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        out = transformer(seq)\n",
        "        if remove_cls:\n",
        "            out = out[1:]\n",
        "        \n",
        "        assert out.shape == target.shape, f\"Output {out.shape} != target {target.shape}\"\n",
        "        \n",
        "        loss = loss_fn(out, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        final_loss = loss.item()\n",
        "        \n",
        "        if epoch % log_interval == 0:\n",
        "            print(f'Step {epoch}: loss {final_loss:.6f}')\n",
        "    \n",
        "    return transformer, final_loss\n",
        "\n",
        "# =============================================================================\n",
        "# Comparison and Testing Functions\n",
        "# =============================================================================\n",
        "def compare_transformers(\n",
        "    hand_transformer: 'NumpyTransformer',\n",
        "    learned_transformer: 'PytorchTransformer',\n",
        "    seq: NDArrayFloat,\n",
        "    plot: bool = True,\n",
        "    save_plot: bool = False,\n",
        "    run_name: Optional[str] = None,\n",
        ") -> Tuple[NDArrayFloat, NDArrayFloat]:\n",
        "    \"\"\"Compare hand-designed and learned transformers visually.\n",
        "    \n",
        "    Args:\n",
        "        hand_transformer: Hand-designed NumpyTransformer.\n",
        "        learned_transformer: Trained PytorchTransformer.\n",
        "        seq: Input sequence.\n",
        "        plot: If True, display plots.\n",
        "        save_plot: If True, save plots to the plots directory.\n",
        "        run_name: Optional run identifier for organizing saved plots.\n",
        "    \"\"\"\n",
        "    assert seq.ndim == 2, f\"seq must be 2D (seq_len, input_dim), got shape {seq.shape}\"\n",
        "    \n",
        "    separator = '=' * 40\n",
        "    print(f'{separator} Hand Designed {separator}')\n",
        "    out_hand = hand_transformer.forward(\n",
        "        seq, verbose=False, plot=plot, \n",
        "        save_plot=save_plot, plot_name=\"hand_designed\", run_name=run_name\n",
        "    )\n",
        "    \n",
        "    assert out_hand.shape[0] == seq.shape[0], \\\n",
        "        f\"Output seq_len {out_hand.shape[0]} != input seq_len {seq.shape[0]}\"\n",
        "\n",
        "    # Extract learned weights (transpose due to PyTorch Linear convention)\n",
        "    py_Km = learned_transformer.Km.weight.T.detach().numpy()\n",
        "    py_Qm = learned_transformer.Qm.weight.T.detach().numpy()\n",
        "    py_Vm = learned_transformer.Vm.weight.T.detach().numpy()\n",
        "    py_pos = None\n",
        "    if learned_transformer.pos is not None:\n",
        "        py_pos = learned_transformer.pos.weight.detach().numpy()\n",
        "\n",
        "    print(f'{separator}    Learned    {separator}')\n",
        "    np_learned = NumpyTransformer(py_Km, py_Qm, py_Vm, py_pos)\n",
        "    out_learned = np_learned.forward(\n",
        "        seq, verbose=False, plot=plot,\n",
        "        save_plot=save_plot, plot_name=\"learned\", run_name=run_name\n",
        "    )\n",
        "    \n",
        "    assert out_learned.shape == out_hand.shape, \\\n",
        "        f\"Shape mismatch: hand={out_hand.shape}, learned={out_learned.shape}\"\n",
        "    \n",
        "    return out_hand, out_learned\n",
        "\n",
        "\n",
        "def test(seed: int = 42) -> None:\n",
        "    \"\"\"Verify NumpyTransformer and PytorchTransformer produce identical outputs.\"\"\"\n",
        "    set_random_seed(seed)\n",
        "    qk_dim = np.random.randint(1, 5)\n",
        "    v_dim = np.random.randint(1, 5)\n",
        "    \n",
        "    for i in range(TEST_ITERATIONS):\n",
        "        Km = np.random.randn(TEST_INPUT_DIM, qk_dim)\n",
        "        Qm = np.random.randn(TEST_INPUT_DIM, qk_dim)\n",
        "        Vm = np.random.randn(TEST_INPUT_DIM, v_dim)\n",
        "        \n",
        "        if i < TEST_ITERATIONS // 2:\n",
        "            pos_dim = np.random.randint(2, 4)\n",
        "            pos = np.random.randn(TEST_MAX_SEQ_LEN, pos_dim)\n",
        "            seq_dim = TEST_INPUT_DIM - pos_dim\n",
        "        else:\n",
        "            pos_dim = None\n",
        "            pos = None\n",
        "            seq_dim = TEST_INPUT_DIM\n",
        "\n",
        "        seq = np.random.randn(np.random.randint(TEST_MIN_SEQ_LEN, TEST_MAX_SEQ_LEN + 1), seq_dim)\n",
        "        out_np = NumpyTransformer(Km, Qm, Vm, pos).forward(seq, verbose=False)\n",
        "        \n",
        "        transformer = PytorchTransformer(seq_dim, qk_dim, v_dim, pos_dim, TEST_MAX_SEQ_LEN)\n",
        "        state_dict = transformer.state_dict()\n",
        "        state_dict['Km.weight'] = torch.FloatTensor(Km.T)\n",
        "        state_dict['Qm.weight'] = torch.FloatTensor(Qm.T)\n",
        "        state_dict['Vm.weight'] = torch.FloatTensor(Vm.T)\n",
        "        if pos is not None:\n",
        "            state_dict['pos.weight'] = torch.FloatTensor(pos)\n",
        "        transformer.load_state_dict(state_dict)\n",
        "        out_py = transformer(torch.FloatTensor(seq)).detach().numpy()\n",
        "        \n",
        "        if not np.allclose(out_np, out_py, rtol=RELATIVE_TOLERANCE):\n",
        "            print('ERROR: Implementation mismatch!')\n",
        "            print(f'NumPy output: {out_np}')\n",
        "            print(f'PyTorch output: {out_py}')\n",
        "            raise ValueError('NumPy and PyTorch outputs do not match')\n",
        "    \n",
        "    print('✓ All equivalence tests passed!')\n",
        "    \n",
        "    # Save test results for grading\n",
        "    set_random_seed(1998)\n",
        "    test_transformer = PytorchTransformer(7, 4, 3, 2, 9)\n",
        "    o = test_transformer(torch.randn(8, 7))\n",
        "    TO_SAVE[\"torch_transformer_shape\"] = list(o.shape)\n",
        "    TO_SAVE[\"torch_transformer_value\"] = o.view(-1).tolist()[2:7]\n",
        "    TO_SAVE[\"torch_transformer_init\"] = inspect.getsource(PytorchTransformer.__init__)\n",
        "    TO_SAVE[\"torch_transformer_forward\"] = inspect.getsource(PytorchTransformer.forward)\n",
        "\n",
        "# =============================================================================\n",
        "# Submission Data Storage\n",
        "# =============================================================================\n",
        "TO_SAVE: dict[str, Any] = {\"time\": time.time()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeWq28n4GxoO"
      },
      "source": [
        "## Implement a Simple Transformer\n",
        "\n",
        "Below, you'll find a simple transformer implementation in Numpy that we have provided for you. It's important to note that this implementation is different from a Transformer in real applications. The differences include:\n",
        "\n",
        "- Only a single layer with a single head is in the network.\n",
        "- There are no residual connections.\n",
        "- There is no normalization or dropout.\n",
        "- We concatenate the positional encoding rather than adding it to the inputs.\n",
        "- There are no activation functions or MLP layers.\n",
        "- It does not support attention masking.\n",
        "- The input is a single sequence instead of a batch. So there is no need to implement padding.\n",
        "\n",
        "To ensure that you understand the transformer model fully, your task is to **implement a PyTorch equivalent model**. You don't need to include the printing and plotting code found in the Numpy version. **You should implement a vectorized version of the attention operation**, meaning that you should calculate all attention scores at once, rather than looping over keys. Once you have completed your implementation, make sure it passes the tests included in the cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViMikCqaPKx4"
      },
      "source": [
        "Implement the `PytorchTransformer` class. It should be identical to the forward pass of the `NumpyTransformer` class.\n",
        "\n",
        "**Hint:** The attention operation should be implemented as:\n",
        "\n",
        "$$\\mathrm{softmax}(\\dfrac{QK^T}{ \\sqrt{d_k}}) \\cdot V$$\n",
        "\n",
        "where the softmax is applied to the last dimension, meaning that the softmax is applied independently to each query's scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCOlp7FOGxoO"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Transformer Implementations\n",
        "===========================\n",
        "NumPy (reference) and PyTorch (student implementation) versions of a\n",
        "simplified single-head, single-layer Transformer.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class NumpyTransformer:\n",
        "    \"\"\"Reference implementation of simplified Transformer in NumPy.\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        Km: NDArrayFloat,\n",
        "        Qm: NDArrayFloat,\n",
        "        Vm: NDArrayFloat,\n",
        "        pos: Optional[NDArrayFloat] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize the NumPy Transformer.\"\"\"\n",
        "        # Dimension validation\n",
        "        assert Km.ndim == 2, f\"Km must be 2D, got shape {Km.shape}\"\n",
        "        assert Qm.ndim == 2, f\"Qm must be 2D, got shape {Qm.shape}\"\n",
        "        assert Vm.ndim == 2, f\"Vm must be 2D, got shape {Vm.shape}\"\n",
        "        assert Km.shape[0] == Qm.shape[0] == Vm.shape[0], \\\n",
        "            f\"Matrices must have same input_dim: Km={Km.shape[0]}, Qm={Qm.shape[0]}, Vm={Vm.shape[0]}\"\n",
        "        assert Km.shape[1] == Qm.shape[1], \\\n",
        "            f\"Km and Qm must have same qk_dim: {Km.shape[1]} vs {Qm.shape[1]}\"\n",
        "        \n",
        "        if pos is not None:\n",
        "            assert pos.ndim == 2, f\"pos must be 2D, got shape {pos.shape}\"\n",
        "        \n",
        "        self.Km = Km\n",
        "        self.Qm = Qm\n",
        "        self.Vm = Vm\n",
        "        self.pos = pos\n",
        "        self.qk_dim = Qm.shape[1]\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        seq: NDArrayFloat,\n",
        "        verbose: bool = False,\n",
        "        plot: bool = False,\n",
        "        save_plot: bool = False,\n",
        "        plot_name: str = \"transformer_attention\",\n",
        "        run_name: Optional[str] = None,\n",
        "    ) -> NDArrayFloat:\n",
        "        \"\"\"Compute forward pass: Attention(Q, K, V) = softmax(QK^T / sqrt(d_k)) @ V\n",
        "        \n",
        "        Args:\n",
        "            seq: Input sequence of shape (seq_len, input_dim).\n",
        "            verbose: If True, print intermediate computation steps.\n",
        "            plot: If True, visualize attention matrices.\n",
        "            save_plot: If True, save the plot to the plots directory.\n",
        "            plot_name: Base name for the saved plot file.\n",
        "            run_name: Optional run identifier for organizing saved plots.\n",
        "        \"\"\"\n",
        "        assert seq.ndim == 2, f\"seq must be 2D (seq_len, input_dim), got shape {seq.shape}\"\n",
        "        \n",
        "        seq_len, input_dim = seq.shape\n",
        "        \n",
        "        # Concatenate positional encodings if provided\n",
        "        if self.pos is not None:\n",
        "            assert seq_len <= self.pos.shape[0], \\\n",
        "                f\"seq_len {seq_len} > max pos length {self.pos.shape[0]}\"\n",
        "            seq = np.concatenate([seq, self.pos[:seq_len]], axis=-1)\n",
        "        \n",
        "        # Project to Q, K, V spaces\n",
        "        K = seq @ self.Km\n",
        "        Q = seq @ self.Qm\n",
        "        V = seq @ self.Vm\n",
        "        \n",
        "        assert K.shape == (seq_len, self.qk_dim), f\"K shape: expected {(seq_len, self.qk_dim)}, got {K.shape}\"\n",
        "        assert Q.shape == (seq_len, self.qk_dim), f\"Q shape: expected {(seq_len, self.qk_dim)}, got {Q.shape}\"\n",
        "        \n",
        "        if verbose:\n",
        "            print(f'K (Keys):\\n{K.tolist()}')\n",
        "            print(f'Q (Queries):\\n{Q.tolist()}')\n",
        "            print(f'V (Values):\\n{V.tolist()}')\n",
        "        \n",
        "        if plot or save_plot:\n",
        "            fig, axs = plt.subplots(nrows=1, ncols=8)\n",
        "            fig.tight_layout()\n",
        "            self._plot_all(axs, K, Q, V)\n",
        "        \n",
        "        # Compute attention (non-vectorized for educational clarity)\n",
        "        outputs = []\n",
        "        attn_weights = []\n",
        "        \n",
        "        for i, q in enumerate(Q):\n",
        "            if verbose:\n",
        "                print(f'Item {i}: Computing attention for query {q}')\n",
        "            \n",
        "            dot = K @ q / np.sqrt(self.qk_dim)\n",
        "            if verbose:\n",
        "                print(f'  Dot products (q · K): {dot}')\n",
        "            \n",
        "            exp_dot = np.exp(dot)\n",
        "            softmax_dot = exp_dot / np.sum(exp_dot)\n",
        "            \n",
        "            if verbose:\n",
        "                print(f'  Attention weights: {softmax_dot}')\n",
        "            \n",
        "            attn_weights.append(softmax_dot)\n",
        "            out_i = softmax_dot @ V\n",
        "            \n",
        "            if verbose:\n",
        "                print(f'  Output: {out_i}')\n",
        "            \n",
        "            outputs.append(out_i)\n",
        "        \n",
        "        if plot or save_plot:\n",
        "            rescale_and_plot(np.array(attn_weights).T, 'Attn', axs[6], x_lab='Q', y_lab='K')\n",
        "            rescale_and_plot(np.array(outputs).T, 'Out', axs[7], x_lab='seq', y_lab='d_v')\n",
        "            if save_plot:\n",
        "                save_figure(fig, plot_name, run_name=run_name)\n",
        "            if plot:\n",
        "                plt.show()\n",
        "            else:\n",
        "                plt.close(fig)\n",
        "        \n",
        "        output = np.array(outputs)\n",
        "        assert output.shape == (seq_len, V.shape[1]), \\\n",
        "            f\"Output shape: expected {(seq_len, V.shape[1])}, got {output.shape}\"\n",
        "        \n",
        "        return output\n",
        "    \n",
        "    def _plot_all(self, axs, K: NDArrayFloat, Q: NDArrayFloat, V: NDArrayFloat) -> None:\n",
        "        \"\"\"Plot weight matrices and K, Q, V projections.\"\"\"\n",
        "        rescale_and_plot(self.Km.T, 'Km', axs[0], x_lab='d_in', y_lab='d_qk')\n",
        "        rescale_and_plot(self.Qm.T, 'Qm', axs[1], x_lab='d_in', y_lab='d_qk')\n",
        "        rescale_and_plot(self.Vm.T, 'Vm', axs[2], x_lab='d_in', y_lab='d_v')\n",
        "        rescale_and_plot(K.T, 'K', axs[3], x_lab='seq', y_lab='d_qk')\n",
        "        rescale_and_plot(Q.T, 'Q', axs[4], x_lab='seq', y_lab='d_qk')\n",
        "        rescale_and_plot(V.T, 'V', axs[5], x_lab='seq', y_lab='d_v')\n",
        "\n",
        "class PytorchTransformer(nn.Module):\n",
        "    \"\"\"PyTorch implementation of simplified single-head Transformer.\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        qk_dim: int,\n",
        "        v_dim: int,\n",
        "        pos_dim: Optional[int] = None,\n",
        "        max_seq_len: int = 10,\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize the PyTorch Transformer.\"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        # Dimension validation\n",
        "        assert input_dim > 0, f\"input_dim must be positive, got {input_dim}\"\n",
        "        assert qk_dim > 0, f\"qk_dim must be positive, got {qk_dim}\"\n",
        "        assert v_dim > 0, f\"v_dim must be positive, got {v_dim}\"\n",
        "        \n",
        "        self._input_dim = input_dim\n",
        "        self._max_seq_len = max_seq_len\n",
        "        \n",
        "        if pos_dim is not None:\n",
        "            self.pos: Optional[nn.Embedding] = nn.Embedding(max_seq_len, pos_dim)\n",
        "        else:\n",
        "            self.pos = None\n",
        "        \n",
        "        total_input_dim = input_dim + (pos_dim if pos_dim is not None else 0)\n",
        "\n",
        "        ########################################################################\n",
        "        # TODO: Define query, key, value projection layers Qm, Km, Vm.\n",
        "        #       Each of them is a linear projection without bias\n",
        "        ########################################################################\n",
        "        ########################################################################\n",
        "\n",
        "        self.d_k = qk_dim\n",
        "\n",
        "    def forward(self, seq) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Transformer forward pass\n",
        "\n",
        "        Inputs: seq is a torch tensor of shape (seq_len, input_dim).\n",
        "        Outputs: a torch tensor of shape (seq_len, v_dim), the output of the attention operation\n",
        "        \"\"\"\n",
        "        out = None\n",
        "        ################################################################################################\n",
        "        # TODO: Implement the forward pass of the `PytorchTransformer` class.\n",
        "        #       The forward pass should be identical to the forward pass of the\n",
        "        #       `NumpyTransformer` class.\n",
        "        #\n",
        "        # Hint: The attention operation should be implemented as\n",
        "        #       If `pos` exists, it should be concatenated to the input sequence.\n",
        "        #################################################################################################\n",
        "        ################################################################################################\n",
        "        # END OF YOUR CODE\n",
        "        ################################################################################################\n",
        "        \n",
        "        assert out.shape[0] == seq_len, f\"Output seq_len {out.shape[0]} != input seq_len {seq_len}\"\n",
        "        return out\n",
        "\n",
        "\n",
        "# Run equivalence tests to verify implementation\n",
        "test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHpybcMyGxoP"
      },
      "source": [
        "## Self-Attention: Attention by Content\n",
        "\n",
        "In this coding homework, we will explore how Transformers can attend to different tokens in a variable-length sequence based on their contents. We will do this by **implementing a Transformer that performs the *identity* operation on a sequence of one-hot vectors**. We will then compare the performance and weights of this hand-coded Transformer with those of a PyTorch model trained on the same task.\n",
        "\n",
        "To hand-design the Transformer, we will **choose values for `Km`, `Qm`, and `Vm` that enable the model to attend to the content of each token in the input sequence**. We will then use this Transformer to process several example data points, and verify that the output matches the input.\n",
        "\n",
        "Once your hand-written Transformer is working correctly, we will run the PyTorch training loop to train a model on the identity operation task. We will then compare the weights and intermediate outputs of this model with those of our hand-coded transformer, and comment on their similarities and differences. Note that when we generate plots, we will rescale the range of the weights and outputs to 0-1, so we can compare their relative values without comparing absolute values.\n",
        "\n",
        "The test cases for our hand-coded transformer are as follows:\n",
        "\n",
        "```\n",
        "Input sequence -->   Output sequence\n",
        "[A, B, C, C]   -->   [A, B, C, C]\n",
        "[C, A, C]      -->   [C, A, C]\n",
        "[B, B, C]      -->   [B, B, C]\n",
        "```\n",
        "\n",
        "We have provided some hints below, but to enhance your understanding of attention and the Transformer, we highly recommend attempting this problem to the best of your abilities before referring to the hints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3wDPVmY3GxoP"
      },
      "outputs": [],
      "source": [
        "#@title Hints\n",
        "\n",
        "# Hint 1: To attend to a specific element, ensure that its pre-softmax score is\n",
        "#         significantly higher than that of the other elements.\n",
        "softmax = lambda x: np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True)\n",
        "print('='*20, 'Hint 1', '='*20)\n",
        "print('Selecting index 0', softmax(np.array([9, 0, 0])))\n",
        "print('Selecting index 1', softmax(np.array([-3, 5, -5])))\n",
        "\n",
        "\n",
        "# Hint 2: Attending to a particular element is more manageable if the keys are\n",
        "#         orthogonal.\n",
        "print('='*20, 'Hint 2', '='*20)\n",
        "keys = np.array([[2, 0], [0, 1]])  # Orthogonal\n",
        "q = np.array([5, 0])\n",
        "print('Selecting index 0', softmax(q @ keys))\n",
        "q = np.array([0, 5])\n",
        "print('Selecting index 1', softmax(q @ keys))\n",
        "\n",
        "\n",
        "# Hint 3: You can use the following helper functions to test the keys, queries,\n",
        "#         and values produced by your matrix for each valid sequence element.\n",
        "#  Km, Qm, Vm, and are the matrices you will define below.\n",
        "all_token_seq = np.eye(3)  # Each row is a sequence element. The identity corresponds to [A, B, C].\n",
        "get_K = lambda: all_token_seq @ Km  # Each row of the output is a key\n",
        "get_Q = lambda: all_token_seq @ Qm  # Each row of the output is a query\n",
        "get_V = lambda: all_token_seq @ Vm  # Each row of the output is a value\n",
        "\n",
        "\n",
        "# Hint 4: To test different attention weights, use the softmax function defined\n",
        "#         above.\n",
        "\n",
        "\n",
        "# Hint 5: When there are repeated elements in a sequence with the same content,\n",
        "#         attending to all of them rather than a single one will be simpler.\n",
        "#         Since they have the same content, taking a \"weighted average\" over\n",
        "#         values weighted by attention scores will produce the same output as\n",
        "#         attending to a single one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VL_SSQeGxoP"
      },
      "outputs": [],
      "source": [
        "# Token definitions (one-hot encodings)\n",
        "A = np.array([1, 0, 0])\n",
        "B = np.array([0, 1, 0])\n",
        "C = np.array([0, 0, 1])\n",
        "tokens = [A, B, C]\n",
        "\n",
        "################################################################################\n",
        "# TODO: Write Numpy arrays for `Km`, `Qm`, and `Vm`.\n",
        "#       The dimensions should be (input_dim, qk_dim), (input_dim, qk_dim), and\n",
        "#       (input_dim, v_dim), respectively.\n",
        "#       In this case, input_dim = 3, and v_dim = 3. qk_dim can be any value you\n",
        "#       choose, but 3 is a reasonable choice.\n",
        "################################################################################\n",
        "############################################ END OF YOUR CODE ##################\n",
        "\n",
        "# Dimension validation\n",
        "assert Km.shape[0] == 3 and Qm.shape[0] == 3 and Vm.shape == (3, 3), \\\n",
        "    f\"Shape error: Km={Km.shape}, Qm={Qm.shape}, Vm={Vm.shape}\"\n",
        "print(f\"✓ Matrices: Km {Km.shape}, Qm {Qm.shape}, Vm {Vm.shape}\")\n",
        "\n",
        "\n",
        "def generate_test_cases_identity(\n",
        "    tokens: List[NDArrayFloat],\n",
        "    max_len: int = 7,\n",
        ") -> Tuple[NDArrayFloat, NDArrayFloat]:\n",
        "    \"\"\"Generate random test cases for identity task.\"\"\"\n",
        "    seq_len = np.random.randint(1, max_len)\n",
        "    input_arr = np.stack(random.choices(tokens, k=seq_len))\n",
        "    return input_arr, input_arr  # Identity: output = input\n",
        "\n",
        "\n",
        "# Test implementation\n",
        "print(\"Running identity task tests...\")\n",
        "for i in range(10):\n",
        "    seq, expected_out = generate_test_cases_identity(tokens)\n",
        "    np_transformer = NumpyTransformer(Km, Qm, Vm)\n",
        "    out = np_transformer.forward(seq)\n",
        "    assert np.allclose(out, expected_out, rtol=RELATIVE_TOLERANCE), \\\n",
        "        f\"Test {i} failed: out shape {out.shape}, max error {np.abs(out - expected_out).max():.6f}\"\n",
        "print(\"✓ All 10 identity tests passed!\")\n",
        "\n",
        "# Save results for grading\n",
        "set_random_seed(1997)\n",
        "seq, _ = generate_test_cases_identity(tokens)\n",
        "np_transformer = NumpyTransformer(Km, Qm, Vm)\n",
        "out = np_transformer.forward(seq, verbose=False)\n",
        "TO_SAVE[\"attention_by_content\"] = out.reshape(-1).tolist()\n",
        "TO_SAVE[\"attention_by_content_Q\"] = Qm.reshape(-1).tolist()\n",
        "TO_SAVE[\"attention_by_content_K\"] = Km.reshape(-1).tolist()\n",
        "TO_SAVE[\"attention_by_content_V\"] = Vm.reshape(-1).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg364J-ZGxoP"
      },
      "outputs": [],
      "source": [
        "# Compare hand-designed and trained transformers\n",
        "def make_batch_identity(tokens: List[NDArrayFloat] = tokens, max_len: int = 7):\n",
        "    \"\"\"Create a training batch for the identity task.\"\"\"\n",
        "    seq, target = generate_test_cases_identity(tokens, max_len=max_len)\n",
        "    return torch.FloatTensor(seq), torch.FloatTensor(target)\n",
        "\n",
        "set_random_seed(227)\n",
        "\n",
        "A = np.array([1, 0, 0])\n",
        "B = np.array([0, 1, 0])\n",
        "C = np.array([0, 0, 1])\n",
        "transformer_py, loss = train_loop(make_batch_identity, input_dim=len(A), qk_dim=Km.shape[1], v_dim=Vm.shape[1])\n",
        "seq = np.stack([A, B, B, C, C])\n",
        "print(\"seq:\", seq)\n",
        "compare_transformers(np_transformer, transformer_py, seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSdv3wOi8K9l"
      },
      "source": [
        "### Question\n",
        "\n",
        "In the figure provided, compare the variables of your hand-designed Transformer with those of the learned Transformer. **Identify the similarities and differences between the two sets of variables and provide a brief explanation for each difference**. Please include your answers in your written submission for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVT0fpt8GxoQ"
      },
      "source": [
        "## Self-Attention: Attention by Position\n",
        "\n",
        "In Transformers, tokens can decide what other tokens to attend to by looking at their positions. In this section, we'll explore how this works by **hand-designing a Transformer for the task of copying the first token of a sequence across the entire sequence.**\n",
        "\n",
        "To accomplish this, we'll add a positional encoding to the input sequence. Transformers typically use a sinusoidal positional encoding or a learned positional encoding, but we'll **set the weight by hand to any value we choose**. These positional encodings will get concatenated to the input sequence inside the Transformer. For simplicity, we'll *concatenate* the positional encoding to the input embeddings instead of adding it.\n",
        "\n",
        "Here are the example data points (where `A`, `B`, and `C` are vectors and `A:pos_0` represents the concatenation between vectors `A` and `pos_0`):\n",
        "\n",
        "```\n",
        "Input sequence --> Input sequence with positional encoding --> Output sequence\n",
        "[A, B, C, C]   --> [A:pos_0, B:pos_1, C:pos_2, C:pos_3]    --> [A, A, A, A]\n",
        "[C, A, C]      --> [C:pos_0, A:pos_1, C:pos_2]             --> [C, C, C]\n",
        "[B, B, C]      --> [B:pos_0, B:pos_1, C:pos_2]             --> [B, B, B]\n",
        "```\n",
        "\n",
        "Once you've passed the test cases, run the training loop below to train the PyTorch model.\n",
        "\n",
        "We have provided some hints below, but to enhance your understanding of attention and the Transformer, we highly recommend attempting this problem to the best of your abilities before referring to the hints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7LLpsxeMGxoQ"
      },
      "outputs": [],
      "source": [
        "#@title Hints\n",
        "\n",
        "# Hint 1: All hints from the previous part still apply.\n",
        "\n",
        "\n",
        "# Hint 2: If you only want to use part of the information in a sequence element,\n",
        "#         choose key/query/value matrices which remove the unwanted information.\n",
        "seq = np.array([[1, 2, 3]])  # A sequence of length 1 with a 3-d element\n",
        "Qm = np.array([[1, 0], [0, 0], [0, 1]])\n",
        "print('Selecting only the first and last vector elements', seq @ Qm)\n",
        "\n",
        "\n",
        "# Hint 3: You can use the following helper functions to test what keys, queries,\n",
        "#         and values would be produced by your matrix.\n",
        "# You will need to provide a sequence (e.g. np.stack([A, B, C])). Km, Qm, Vm, and pos are the matrices you will define below.\n",
        "get_K = lambda seq: np.concatenate([seq, pos[:seq.shape[0]]], axis=1) @ Km # Each row of the output is a key\n",
        "get_Q = lambda seq: np.concatenate([seq, pos[:seq.shape[0]]], axis=1) @ Qm # Each row of the output is a query\n",
        "get_V = lambda seq: np.concatenate([seq, pos[:seq.shape[0]]], axis=1) @ Vm # Each row of the output is a value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0BIL6FjGxoQ"
      },
      "outputs": [],
      "source": [
        "A = np.array([1, 0, 0])\n",
        "B = np.array([0, 1, 0])\n",
        "C = np.array([0, 0, 1])\n",
        "tokens = [A, B, C]\n",
        "\n",
        "################################################################################\n",
        "# TODO: Implement numpy arrays for Km, Qm, and Vm and pos.\n",
        "#       The shape of Km, and Qm are [input_dim + pos_dim, qk_dim].\n",
        "#       The shape of Vm is [input_dim + pos_dim, v_dim].\n",
        "#       The shape of pos is [max_len, pos_dim].\n",
        "#       In this case, input_dim = 3, and v_dim = 3. qk_dim can be any value you\n",
        "#       choose, but 1 is a reasonable choice. max_len is the maximum sequence\n",
        "#       length you will encounter, 4 in this case.\n",
        "#       pos_dim can be any value you choose, but 4 is a resonable choice.\n",
        "################################################################################\n",
        "############################################ END OF YOUR CODE ##################\n",
        "\n",
        "# Dimension validation\n",
        "pos_dim = pos.shape[1]\n",
        "total_dim = 3 + pos_dim\n",
        "assert Km.shape[0] == total_dim and Qm.shape[0] == total_dim and Vm.shape == (total_dim, 3), \\\n",
        "    f\"Shape error: Km={Km.shape}, Qm={Qm.shape}, Vm={Vm.shape}, expected input_dim={total_dim}\"\n",
        "print(f\"✓ Matrices: pos {pos.shape}, Km {Km.shape}, Qm {Qm.shape}, Vm {Vm.shape}\")\n",
        "\n",
        "\n",
        "def generate_test_cases_first(\n",
        "    tokens: List[NDArrayFloat],\n",
        "    max_len: int = 5,\n",
        ") -> Tuple[NDArrayFloat, NDArrayFloat]:\n",
        "    \"\"\"Generate test cases for copy-first-token task.\"\"\"\n",
        "    seq_len = np.random.randint(1, max_len)\n",
        "    input_arr = np.stack(random.choices(tokens, k=seq_len))\n",
        "    expected_out = np.stack([input_arr[0]] * seq_len)\n",
        "    return input_arr, expected_out\n",
        "\n",
        "\n",
        "# Test implementation\n",
        "print(\"Running copy-first-token task tests...\")\n",
        "for i in range(10):\n",
        "    seq, expected_out = generate_test_cases_first(tokens)\n",
        "    np_transformer = NumpyTransformer(Km, Qm, Vm, pos=pos)\n",
        "    out = np_transformer.forward(seq)\n",
        "    assert np.allclose(out, expected_out, rtol=RELATIVE_TOLERANCE), \\\n",
        "        f\"Test {i} failed: max error {np.abs(out - expected_out).max():.6f}\"\n",
        "print(\"✓ All 10 copy-first-token tests passed!\")\n",
        "\n",
        "# Save results for grading\n",
        "set_random_seed(2017)\n",
        "seq, _ = generate_test_cases_first(tokens)\n",
        "np_transformer = NumpyTransformer(Km, Qm, Vm, pos=pos)\n",
        "out = np_transformer.forward(seq)\n",
        "TO_SAVE[\"attention_by_position\"] = out.reshape(-1).tolist()\n",
        "TO_SAVE[\"attention_by_position_pos\"] = pos.reshape(-1).tolist()\n",
        "TO_SAVE[\"attention_by_position_Q\"] = Qm.reshape(-1).tolist()\n",
        "TO_SAVE[\"attention_by_position_K\"] = Km.reshape(-1).tolist()\n",
        "TO_SAVE[\"attention_by_position_V\"] = Vm.reshape(-1).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o4cVzJQGxoQ"
      },
      "outputs": [],
      "source": [
        "# Compare hand-designed and trained transformers\n",
        "def make_batch_first(tokens: List[NDArrayFloat] = tokens, max_len: int = 5):\n",
        "    \"\"\"Create a training batch for the copy-first-token task.\"\"\"\n",
        "    seq, target = generate_test_cases_first(tokens, max_len=max_len)\n",
        "    return torch.FloatTensor(seq), torch.FloatTensor(target)\n",
        "\n",
        "pos_dim = pos.shape[1]\n",
        "transformer_py, loss = train_loop(make_batch_first, input_dim=len(A), qk_dim=Km.shape[1], v_dim=Vm.shape[1], pos_dim=pos_dim, max_seq_len=pos.shape[0])\n",
        "seq = np.stack([A, B, B])\n",
        "out_np, out_py = compare_transformers(np_transformer, transformer_py, seq)\n",
        "print(\"seq:\", seq)\n",
        "print(f'Out (Hand designed) \\n {np.round(out_np, 2)}')\n",
        "print(f'Out (Learned) \\n {np.round(out_py, 2)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BZmWbR99Faw"
      },
      "source": [
        "### Question\n",
        "\n",
        "In the figure provided, compare the variables of your hand-designed Transformer with those of the learned Transformer. **Identify the similarities and differences between the two sets of variables and provide a brief explanation for each.** Please include your findings in your written submission for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz-GhgQF7Vqc"
      },
      "source": [
        "## Generate the Submission Log\n",
        "\n",
        "Please download `submission_log.json` and submit it to Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbZt6owz7ZRM"
      },
      "outputs": [],
      "source": [
        "with open(\"submission_log.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(TO_SAVE, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdVx3sG7GxoQ"
      },
      "source": [
        "## (Optional) Self-Attention: Attention by Content and Positoin\n",
        "\n",
        "Finally, we'll explore how transformers can attend to tokens by looking at both their position and their content. In this section, we'll design a transformer for the following task: given a sequence of tokens, output a positive number for every unique token and a negative number for every repeated token.\n",
        "\n",
        "To make implementing this easier, we'll add a CLS token to the beginning of the sequence. We will ignore the output of the CLS token index, which means we can use the CLS token to represent whatever we want. (In practice, the CLS token is often thought of as a representation of the entire sequence, but you can use it however is useful.)\n",
        "\n",
        "\n",
        "\\# Example data points (in each case, A, B, and C are vectors. A:pos_0 represents concatenation between vectors A and pos_0. The target outputs shown are +/-1, but any number with the right sign is fine. \"Ignore\" means that the output can be anything and will not be used to compute the loss.): \\\n",
        "Input sequence --> Input sequence with CLS and pos encoding --> Output sequence \\\n",
        "[A, B, C, C] --> [CLS: pos_0, A:pos_1, B:pos_2, C:pos_3, C:pos_4] --> [Ignore, 1, 1, -1, -1] \\\n",
        "[C, A, C] --> [CLS: pos_0, C:pos_1, A:pos_2, C:pos_3] --> [Ignore, -1, 1, 1] \\\n",
        "[B, B, C] --> [CLS: pos_0, B:pos_1, B:pos_2, C:pos_3] --> [Ignore, -1, -1, 1]\n",
        "\n",
        "\n",
        "Once the test cases pass, run the training loop below a few times to train the PyTorch model. Comment on the similarities and differences between the weights and intermediate outputs of the learned and hand-coded model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-zAzr_1GxoQ"
      },
      "outputs": [],
      "source": [
        "A = np.array([1, 0, 0, 0])\n",
        "B = np.array([0, 1, 0, 0])\n",
        "C = np.array([0, 0, 1, 0])\n",
        "CLS = np.array([0, 0, 0, 1])\n",
        "tokens = [A, B, C]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_2koMEoGxoQ"
      },
      "outputs": [],
      "source": [
        "# Hints (feel free to ignore this block if it's not useful)\n",
        "\n",
        "# Hint 1: All hints from the previous part still apply.\n",
        "\n",
        "# Hint 2: To check if an array is unique, use what you discovered in the \"select by content\" part to find rows with the same value and\n",
        "# what you learned in the \"select by position\" part to NOT select the key which comes from the same position as the query.\n",
        "\n",
        "# Hint 3: If you need an offset value, consider using the CLS token The CLS token is the first token in a sequence, and it is orthogonal\n",
        "# to all other tokens. This means you can create a query or value which selects it but not any othe token (e.g. by putting 0s in all\n",
        "# indexes except the index where only CLS has a 1).\n",
        "\n",
        "# Hint 4: You can use the following helper functions to test what keys, queries, and values would be produced by your matrix.\n",
        "# You will need to provide a sequence (e.g. np.stack([A, B, C])). Km, Qm, Vm, and pos are the matrices you will define below.\n",
        "get_K = lambda seq: np.concatenate([np.stack([CLS] + list(seq)), pos[:seq.shape[0]+1]], axis=1) @ Km # Each row of the output is a key\n",
        "get_Q = lambda seq: np.concatenate([np.stack([CLS] + list(seq)), pos[:seq.shape[0]+1]], axis=1) @ Qm # Each row of the output is a query\n",
        "get_V = lambda seq: np.concatenate([np.stack([CLS] + list(seq)), pos[:seq.shape[0]+1]], axis=1) @ Vm # Each row of the output is a value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTlGNa3ZGxoQ"
      },
      "outputs": [],
      "source": [
        "################################################################################################\n",
        "# TODO: Implement numpy arrays for Km, Qm, and Vm and pos.\n",
        "#      The dimensions of Km, and Qm are (input_dim + pos_dim, qk_dim).\n",
        "#      The dimensions of Vm are (input_dim + pos_dim, v_dim).\n",
        "#      The dimensions of pos are (max_len + 1, pos_dim). (Each row is a position vector.)\n",
        "#      In this case, input_dim = 4, and v_dim = 1. qk_dim can be any value you choose, but 8 is\n",
        "#      a reasonable choice. max_len is the maximum sequence length you will encounter (before CLS is added),\n",
        "#      4 in this case.  pos_dim can be any value you choose, but 4 is a reasonable choice.\n",
        "#################################################################################################\n",
        "############################################ END OF YOUR CODE ####################################\n",
        "\n",
        "def generate_test_cases_unique(tokens: List[NDArrayFloat], max_len: int = 5):\n",
        "    \"\"\"Generate test cases for unique token detection.\"\"\"\n",
        "    seq_len = np.random.randint(1, max_len)\n",
        "    input_arr = np.stack(random.choices(tokens, k=seq_len))\n",
        "    expected_out = np.stack([1 if np.sum(np.min(input_arr == x, axis=1)) == 1 else -1 for x in input_arr]).reshape(-1, 1)\n",
        "    input_arr = np.stack([CLS] + list(input_arr))\n",
        "    return input_arr, expected_out\n",
        "\n",
        "\n",
        "# Test implementation\n",
        "print(\"Running unique token detection tests...\")\n",
        "for i in range(10):\n",
        "    seq, expected_out = generate_test_cases_unique([A, B, C])\n",
        "    np_transformer = NumpyTransformer(Km, Qm, Vm, pos)\n",
        "    out = np_transformer.forward(seq)\n",
        "    assert np.allclose(np.sign(out[1:]), expected_out, rtol=RELATIVE_TOLERANCE), \\\n",
        "        f\"Test {i} failed: got {np.sign(out[1:]).flatten()}, expected {expected_out.flatten()}\"\n",
        "print(\"✓ All 10 unique token detection tests passed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLIk3vupGxoQ"
      },
      "outputs": [],
      "source": [
        "# Compare hand-designed and trained transformers\n",
        "# Note: The PyTorch model must output exactly +/-1, not just the sign.\n",
        "def make_batch_unique(tokens: List[NDArrayFloat] = tokens, max_len: int = 5):\n",
        "    seq, target = generate_test_cases_unique(tokens, max_len=max_len)\n",
        "    return torch.FloatTensor(seq), torch.FloatTensor(target)\n",
        "\n",
        "pos_dim = pos.shape[1]\n",
        "transformer_py, loss = train_loop(make_batch_unique, input_dim=len(A), qk_dim=Km.shape[1], v_dim=Vm.shape[1], pos_dim=pos_dim, max_seq_len=pos.shape[0], remove_cls=True)\n",
        "seq = np.stack([CLS, A, B, C, C])\n",
        "expected_out = np.stack([1, 1, -1, -1]).reshape(-1, 1)\n",
        "out_npy, out_pyt = compare_transformers(np_transformer, transformer_py, seq)\n",
        "out_npy = np.sign(out_npy[1:])\n",
        "out_pyt = np.sign(out_pyt[1:])\n",
        "\n",
        "# Visualize comparison (CLS token excluded)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(out_npy.T, vmin=-1, vmax=1)\n",
        "plt.title('Hand-Designed Transformer')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.xlabel('Sequence')\n",
        "plt.ylabel('Output')\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(out_pyt.T, vmin=-1, vmax=1)\n",
        "plt.title('Trained Transformer')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.xlabel('Sequence')\n",
        "plt.ylabel('Output')\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(expected_out.T, vmin=-1, vmax=1)\n",
        "plt.title('Expected Output')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.xlabel('Sequence')\n",
        "plt.ylabel('Output')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "76aef98d70e29989e1a4ce576d34e3448c9f030ed463b043b3fd7ce353643fc4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
